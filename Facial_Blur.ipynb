{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Facial_Blur.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/colinmsnow/ModSimPy/blob/master/Facial_Blur.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qag1NL_FWy88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hey! this is wacky!!\n",
        "# can you see this?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t20OdGNZI7l",
        "colab_type": "text"
      },
      "source": [
        "yooo can you see me writing this?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4x1Y1xtZMAi",
        "colab_type": "code",
        "outputId": "18ec1b4b-9ec2-41e1-8a61-d888edc04198",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "!pip install torchviz\n",
        "# !CUDA_LAUNCH_BLOCKING=1\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.autograd import Variable\n",
        "from torchviz import make_dot\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np # we always love numpy\n",
        "import time\n",
        "import gdown\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "gdown.download('https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/The%20Eiffel%20Tower.npy', 'eiffeltower.npy', False)\n",
        "gdown.download('https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bear.npy', 'bear.npy', False)\n",
        "gdown.download('https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/airplane.npy', 'airplane.npy', False)\n",
        "gdown.download('https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/broccoli.npy', 'broccoli.npy', False)\n",
        "gdown.download('https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dog.npy', 'dog.npy', False)\n",
        "gdown.download('https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/broom.npy', 'broom.npy', False)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.2.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.16.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/The%20Eiffel%20Tower.npy\n",
            "To: /content/eiffeltower.npy\n",
            "100%|██████████| 106M/106M [00:00<00:00, 221MB/s] \n",
            "Downloading...\n",
            "From: https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bear.npy\n",
            "To: /content/bear.npy\n",
            "100%|██████████| 106M/106M [00:00<00:00, 197MB/s] \n",
            "Downloading...\n",
            "From: https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/airplane.npy\n",
            "To: /content/airplane.npy\n",
            "100%|██████████| 119M/119M [00:00<00:00, 174MB/s]\n",
            "Downloading...\n",
            "From: https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/broccoli.npy\n",
            "To: /content/broccoli.npy\n",
            "100%|██████████| 104M/104M [00:00<00:00, 172MB/s]  \n",
            "Downloading...\n",
            "From: https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/dog.npy\n",
            "To: /content/dog.npy\n",
            "100%|██████████| 119M/119M [00:00<00:00, 218MB/s]\n",
            "Downloading...\n",
            "From: https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/broom.npy\n",
            "To: /content/broom.npy\n",
            "100%|██████████| 91.7M/91.7M [00:00<00:00, 211MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'broom.npy'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqPERGQfVgc7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tower = np.load('eiffeltower.npy') #type = 1\n",
        "bear = np.load('bear.npy') # type = 0\n",
        "airplane = np.load('airplane.npy')\n",
        "broccoli = np.load('broccoli.npy')\n",
        "dog = np.load('dog.npy')\n",
        "broom = np.load('broom.npy')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICO8bUo6V2He",
        "colab_type": "code",
        "outputId": "52d3511c-cacb-4aed-daba-ec4657fcb0d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "X = airplane[750]\n",
        "X = np.resize(X,(28,28))\n",
        "X = np.invert(X)\n",
        "plt.imshow(X, cmap=\"gray\")\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnoRPCJ8wWgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7yhVEn8Ql_h",
        "colab_type": "code",
        "outputId": "4b59c856-1b6e-4cec-83f9-d3d3f3877d96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "import torch\n",
        "\n",
        "# class QuickDrawData(Dataset):\n",
        "#     def __init__(self, tower, bear, airplane, broccoli):\n",
        "#         super(QuickDrawData, self).__init__()\n",
        "#         self.data = np.vstack((tower, bear, airplane, broccoli))\n",
        "#         self.targets = np.concatenate((0*np.ones(tower.shape[0]), 1*np.ones(bear.shape[0]), 2*np.ones(airplane.shape[0]), 3*np.ones(broccoli.shape[0])))\n",
        "#         print(len(self.data))\n",
        "#         self.classes = ['tower', 'bear', 'airplane', 'broccoli']\n",
        "    \n",
        "#     def __len__(self):\n",
        "#         return self.targets.shape[0]\n",
        "    \n",
        "#     def __getitem__(self, index):\n",
        "#         return torch.FloatTensor(self.data[index, :].reshape((28, 28))).unsqueeze(0), int(self.targets[index])\n",
        "class QuickDrawData(Dataset):\n",
        "    def __init__(self, *args):\n",
        "        super(QuickDrawData, self).__init__()\n",
        "        count = 0\n",
        "        # self.data = np.empty(args[0].shape, dtype=int)\n",
        "        # self.targets = np.empty(args[0].shape, dtype=int)\n",
        "        self.classes = []\n",
        "        for arg in args:\n",
        "          # print(str(arg))\n",
        "          if type(arg) == str:\n",
        "            self.classes += arg\n",
        "          else:\n",
        "\n",
        "            if count == 0:\n",
        "              print(arg.shape)\n",
        "              self.data = np.array(arg)\n",
        "              self.targets = np.array(0*np.ones(arg.shape[0], dtype = int))\n",
        "              print(self.targets)\n",
        "              print(type(self.targets))\n",
        "              print(type(self.data))\n",
        "              print(type(self.classes))\n",
        "            else:\n",
        "              self.data = np.vstack((self.data, arg))\n",
        "              print(int(count)*np.ones(arg.shape[0], dtype = int))\n",
        "              print(self.targets)\n",
        "              self.targets = np.hstack((self.targets, int(count)*np.ones(arg.shape[0], dtype = int)))\n",
        "            count+=1\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.targets.shape[0]\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return torch.FloatTensor(self.data[index, :].reshape((28, 28))).unsqueeze(0), int(self.targets[index])\n",
        "\n",
        "quick_draw_data = QuickDrawData(tower, bear, airplane, broccoli, dog, broom, 'tower', 'bear', 'airplane', 'brocolli', 'dog', 'broom')\n",
        "\n",
        "im, target = quick_draw_data[55102]\n",
        "plt.imshow(im.squeeze(), cmap='gray')\n",
        "plt.show()\n",
        "im.shape\n",
        "print(target)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(134801, 784)\n",
            "[0 0 0 ... 0 0 0]\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'list'>\n",
            "[1 1 1 ... 1 1 1]\n",
            "[0 0 0 ... 0 0 0]\n",
            "[2 2 2 ... 2 2 2]\n",
            "[0 0 0 ... 1 1 1]\n",
            "[3 3 3 ... 3 3 3]\n",
            "[0 0 0 ... 2 2 2]\n",
            "[4 4 4 ... 4 4 4]\n",
            "[0 0 0 ... 3 3 3]\n",
            "[5 5 5 ... 5 5 5]\n",
            "[0 0 0 ... 4 4 4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADjlJREFUeJzt3X+sVPWZx/HPg0BAfgiWSAjggg1R\nq3+AXnHN3hg2XSprapCYXCFGqTGlRkwkaYyG/WP9T7PZ0jSSYG6VFEwXMGlVEpStSzAuCTZcjSuK\nUFyEAPKjjTVQUJDLs3/cY/dW73zPMOfMnLn3eb+SmztznnNmngx87jkz3zPna+4uAPEMq7oBANUg\n/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHghreyiczM04nBJrM3a2e9Qrt+c1sgZntM7OPzezJ\nIo8FoLWs0XP7zewySX+QNF/SEUm7JC1x9z2JbdjzA03Wij3/XEkfu/sBdz8vaaOkhQUeD0ALFQn/\nVEmH+90/ki37G2a2zMx6zKynwHMBKFnTP/Bz925J3RKH/UA7KbLnPypper/707JlAAaBIuHfJWmW\nmc00s5GSFkvaXE5bAJqt4cN+d79gZo9K+k9Jl0la6+4fltYZ2sI111yTrN96663J+oYNG8psByUq\n9J7f3V+T9FpJvQBoIU7vBYIi/EBQhB8IivADQRF+ICjCDwTV8Lf6GnoyTu8ddA4dOpSsX3XVVcn6\n6NGjy2wHdWjJ9/kBDF6EHwiK8ANBEX4gKMIPBEX4gaBaeulutJ/Ozs5k/eqrry70+Pfff3/N2osv\nvljosVEMe34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIqv9Aa3ffv2ZH3mzJnJ+v79+5P11KW9Z8+e\nndz2wIEDyToGxld6ASQRfiAowg8ERfiBoAg/EBThB4Ii/EBQhcb5zeygpNOSeiVdcPeOnPUZ52+x\nBQsWJOuvv/56sv7ggw8m61u3bk3WU+cBrF+/Prnt8uXLk3UMrN5x/jIu5vGP7v6nEh4HQAtx2A8E\nVTT8Lul3ZvaOmS0royEArVH0sL/T3Y+a2VWS3jCzve7+Vv8Vsj8K/GEA2kyhPb+7H81+n5T0sqS5\nA6zT7e4deR8GAmithsNvZmPMbNzXtyX9QNIHZTUGoLmKHPZPlvSymX39OP/h7ulxHwBtg+/zD3Ev\nvfRSst7RkX43NmvWrGS9t7c3WX/uuedq1u67777ktlOnTk3WT506laxHxff5ASQRfiAowg8ERfiB\noAg/EBThB4JiqG+Iy7u09s6dO5P1Bx54oNDzp4YSd+3aldx20aJFyforr7zSUE9DHUN9AJIIPxAU\n4QeCIvxAUIQfCIrwA0ERfiCoMq7ei4qNHDmyZm3GjBnJbfO+8jtx4sRk/csvv0zWR40aVbN28eLF\n5LbXXnttso5i2PMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCM8w8BXV1dNWvDh6f/iVeuXFmoXsS5\nc+eSdcb5m4s9PxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ElTvOb2ZrJf1Q0kl3vzFbdqWkTZJmSDoo\nqcvd/9y8NpGyd+/ehrddvXp1sr579+5kfcKECcl6at6Ahx9+OLkt4/zNVc+e/1eSFnxj2ZOStrn7\nLEnbsvsABpHc8Lv7W5I++8bihZLWZbfXSbq75L4ANFmj7/knu/ux7PZxSZNL6gdAixQ+t9/dPTUH\nn5ktk7Ss6PMAKFeje/4TZjZFkrLfJ2ut6O7d7t7h7rVnbATQco2Gf7OkpdntpZJeLacdAK2SG34z\n2yBpp6RrzeyImT0k6RlJ881sv6R/yu4DGERy3/O7+5Iape+X3AsalHf9+5QtW7Yk61u3bm34sfPM\nmzcvWb/33nub9tzgDD8gLMIPBEX4gaAIPxAU4QeCIvxAUFy6ewjIuzx3yoULF0rs5NJ8/vnnyfr4\n8eNb1ElM7PmBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjG+YeAESNGNLztV199VWInl+aLL75I1keN\nGpWsDxuW3ncV+apzBOz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAoxvmHgCLj/DfddFPTHluSzp8/\nX7N22223Jbc1s2R99OjRyfqZM2eS9ejY8wNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAULnj/Ga2VtIP\nJZ109xuzZU9J+rGkP2arrXT315rVJNKuv/76hrddtWpViZ1cGncvtP3ll1+erDPOn1bPnv9XkhYM\nsPzn7j47+yH4wCCTG353f0vSZy3oBUALFXnP/6iZvW9ma81sYmkdAWiJRsO/RtJ3Jc2WdEzSz2qt\naGbLzKzHzHoafC4ATdBQ+N39hLv3uvtFSb+UNDexbre7d7h7R6NNAihfQ+E3syn97i6S9EE57QBo\nlXqG+jZImidpkpkdkfSvkuaZ2WxJLumgpJ80sUcATZAbfndfMsDiF5rQCxqUur593lj67bffnqzn\nXVs/z4QJE2rWbrnlluS2Tz/9dLKeN86PNM7wA4Ii/EBQhB8IivADQRF+ICjCDwTFpbuHgBtuuKFm\n7fDhw8ltd+zYUXY7dRs7dmyh7fMu3Y009vxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBTj/INA3jTZ\nd9xxR83azp07y26nNGfPni20fdHzBKJjzw8ERfiBoAg/EBThB4Ii/EBQhB8IivADQTHO3wbyxvHv\nueeeZH3atGk1a2vWrGmop1YoOs7PpbuLYc8PBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0FZ3hTOZjZd\n0npJkyW5pG53/4WZXSlpk6QZkg5K6nL3P+c8VvrJhqgxY8Yk68ePH0/Whw9Pn46R+jfcs2dPctsr\nrrgiWR82rNj+ITUWnzdOP378+GQ97zyBJ554omZt9erVyW0HM3e3etar51/2gqSfuvv3JP29pOVm\n9j1JT0ra5u6zJG3L7gMYJHLD7+7H3P3d7PZpSR9JmippoaR12WrrJN3drCYBlO+SjunMbIakOZJ+\nL2myux/LSsfV97YAwCBR97n9ZjZW0m8krXD3U2b//7bC3b3W+3kzWyZpWdFGAZSrrj2/mY1QX/B/\n7e6/zRafMLMpWX2KpJMDbevu3e7e4e4dZTQMoBy54be+XfwLkj5y91X9SpslLc1uL5X0avntAWiW\neg77/0HS/ZJ2m9l72bKVkp6R9JKZPSTpkKSu5rQ4+J05cyZZf/7555P1FStWJOs9PT01a5988kly\n23PnziXrRb92mxqGPH36dHLbRx55JFk/cOBAsr59+/ZkPbrc8Lv7Dkm1xg2/X247AFqFM/yAoAg/\nEBThB4Ii/EBQhB8IivADQXHp7haYNGlSsr548eJk/e23307WOzs7a9Z6e3uT27az/qeQDyTvPIBP\nP/20zHaGHPb8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBU7qW7S32yoJfu3rRpU7J+1113Jetz5sxJ\n1vft23fJPQ0G1113XbKed1nyxx57rGbt2WefbainwaDMS3cDGIIIPxAU4QeCIvxAUIQfCIrwA0ER\nfiAovs9fgnnz5iXrXV3pKQ0ef/zxZH2ojuPn2bt3b7K+ZcuWZH3atGlltjPksOcHgiL8QFCEHwiK\n8ANBEX4gKMIPBEX4gaByv89vZtMlrZc0WZJL6nb3X5jZU5J+LOmP2aor3f21nMcakt/n37hxY7I+\nf/78ZH369OnJ+tmzZy+5J8RV7/f56znJ54Kkn7r7u2Y2TtI7ZvZGVvu5u/97o00CqE5u+N39mKRj\n2e3TZvaRpKnNbgxAc13Se34zmyFpjqTfZ4seNbP3zWytmU2ssc0yM+sxs55CnQIoVd3hN7Oxkn4j\naYW7n5K0RtJ3Jc1W35HBzwbazt273b3D3TtK6BdASeoKv5mNUF/wf+3uv5Ukdz/h7r3uflHSLyXN\nbV6bAMqWG37rmyr1BUkfufuqfsun9FttkaQPym8PQLPUM9TXKem/Je2WdDFbvFLSEvUd8rukg5J+\nkn04mHqsITnUd/PNNyfr48aNS9bffPPNErtBdKUN9bn7DkkDPVhyTB9Ae+MMPyAowg8ERfiBoAg/\nEBThB4Ii/EBQTNENDDFM0Q0gifADQRF+ICjCDwRF+IGgCD8QFOEHgmr1FN1/knSo3/1J2bJ21K69\ntWtfEr01qsze/q7eFVt6ks+3ntysp12v7deuvbVrXxK9Naqq3jjsB4Ii/EBQVYe/u+LnT2nX3tq1\nL4neGlVJb5W+5wdQnar3/AAqUkn4zWyBme0zs4/N7MkqeqjFzA6a2W4ze6/qKcayadBOmtkH/ZZd\naWZvmNn+7PeA06RV1NtTZnY0e+3eM7M7K+ptupltN7M9ZvahmT2WLa/0tUv0Vcnr1vLDfjO7TNIf\nJM2XdETSLklL3H1PSxupwcwOSupw98rHhM3sdkl/kbTe3W/Mlv2bpM/c/ZnsD+dEd3+iTXp7StJf\nqp65OZtQZkr/maUl3S3pR6rwtUv01aUKXrcq9vxzJX3s7gfc/bykjZIWVtBH23P3tyR99o3FCyWt\ny26vU99/npar0VtbcPdj7v5udvu0pK9nlq70tUv0VYkqwj9V0uF+94+ovab8dkm/M7N3zGxZ1c0M\nYHK/mZGOS5pcZTMDyJ25uZW+MbN027x2jcx4XTY+8Pu2Tne/SdI/S1qeHd62Je97z9ZOwzV1zdzc\nKgPMLP1XVb52jc54XbYqwn9U0vR+96dly9qCux/Nfp+U9LLab/bhE19Pkpr9PllxP3/VTjM3DzSz\ntNrgtWunGa+rCP8uSbPMbKaZjZS0WNLmCvr4FjMbk30QIzMbI+kHar/ZhzdLWprdXirp1Qp7+Rvt\nMnNzrZmlVfFr13YzXrt7y38k3am+T/z/V9K/VNFDjb6ukfQ/2c+HVfcmaYP6DgO/Ut9nIw9J+o6k\nbZL2S/ovSVe2UW8vqm825/fVF7QpFfXWqb5D+vclvZf93Fn1a5foq5LXjTP8gKD4wA8IivADQRF+\nICjCDwRF+IGgCD8QFOEHgiL8QFD/B8Pzhyim7SBFAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi8X_pFZAcm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9fMDbMQBAdAc",
        "colab": {}
      },
      "source": [
        "# from torch.utils.data import Dataset\n",
        "# from torch.utils.data import random_split\n",
        "\n",
        "# import torch\n",
        "\n",
        "# class QuickDrawData(Dataset):\n",
        "#     def __init__(self,airplane, broccoli):\n",
        "#         super(QuickDrawData, self).__init__()\n",
        "#         self.data = np.vstack((airplane, broccoli))\n",
        "#         self.targets = np.concatenate((0*np.ones(airplane.shape[0]), 1*np.ones(broccoli.shape[0])))\n",
        "#         print(len(self.data))\n",
        "#         # self.classes = ['tower', 'bear', 'airplane', 'broccoli']\n",
        "#         self.classes = ['airplane', 'broccoli']\n",
        "    \n",
        "#     def __len__(self):\n",
        "#         return self.targets.shape[0]\n",
        "    \n",
        "#     def __getitem__(self, index):\n",
        "#         return torch.FloatTensor(self.data[index, :].reshape((28, 28))).unsqueeze(0), int(self.targets[index])\n",
        "\n",
        "# quick_draw_data = QuickDrawData(airplane, broccoli)\n",
        "\n",
        "# im, target = quick_draw_data[502]\n",
        "# plt.imshow(im.squeeze(), cmap='gray')\n",
        "# plt.show()\n",
        "# im.shape\n",
        "# print(target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbaebNQ7RwG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = int(len(quick_draw_data)*.9)\n",
        "train, test = random_split(quick_draw_data, [x,(len(quick_draw_data) - x)])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMrsY0PERwJV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data set information\n",
        "\n",
        "image_dims = 1, 28, 28\n",
        "n_training_samples = len(train) # How many training images to use\n",
        "n_test_samples = len(test) # How many test images to use\n",
        "classes = ('tower', 'bear', 'airplane', 'brocolli', 'dog', 'broom')\n",
        "\n",
        "# Load the training set\n",
        "train_set = train\n",
        "train_sampler = SubsetRandomSampler(\n",
        "    np.arange(n_training_samples, dtype=np.int64))\n",
        "\n",
        "#Load the test set\n",
        "test_set = test\n",
        "test_sampler = SubsetRandomSampler(np.arange(n_test_samples, dtype=np.int64))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Dv6-ImXRwMA",
        "colab_type": "code",
        "outputId": "bb5c1edb-3a1b-4c70-954c-86e1adc02d9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(test_set)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataset.Subset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QoJj27WRwO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyCNN(nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(MyCNN, self).__init__()\n",
        "    \n",
        "    num_kernels = 16\n",
        "    \n",
        "    self.conv1 = nn.Conv2d(1, num_kernels, kernel_size=3, stride=1, padding=1)\n",
        "    self.pool1 = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0)\n",
        "    self.conv2 = nn.Conv2d(num_kernels, num_kernels*2, kernel_size=3, stride=1, padding=1)\n",
        "    self.pool2 = nn.MaxPool2d(kernel_size = 2, stride = 2, padding = 0)\n",
        "    self.maxpool_output_size1 = int(num_kernels*(image_dims[1]/2) * (image_dims[2]/2))\n",
        "    self.maxpool_output_size2 = int(num_kernels*(image_dims[1]/4) * (image_dims[2]/4)*2)\n",
        "    \n",
        "    \n",
        "    fcl_size = 64\n",
        "    self.fc1 = nn.Linear(1568, fcl_size)\n",
        "    self.activation_func = torch.nn.ReLU()\n",
        "    # fc2_size = fcl_size\n",
        "\n",
        "    self.fc2 = nn.Linear(fcl_size, fcl_size)\n",
        "    # self.fc7 = nn.Linear(fcl_size, fcl_size)\n",
        "\n",
        "    self.activation_func = torch.nn.ReLU()\n",
        "\n",
        "    fc3_size = len(classes)\n",
        "    # fc3_size = 6\n",
        "    self.fc3 = nn.Linear(fcl_size, fc3_size)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = self.conv1(x)\n",
        "\n",
        "    x = self.activation_func(x)\n",
        "\n",
        "    x = self.pool1(x)\n",
        "\n",
        "    x = self.conv2(x)\n",
        "\n",
        "    x = self.activation_func(x)\n",
        "\n",
        "    x = self.pool2(x)\n",
        "\n",
        "    # x = self.pool1(x)\n",
        "    # x = self.activation_func(x)\n",
        "    # x = x.view(-1, self.maxpool_output_size1)\n",
        "    # x = self.pool2(x)\n",
        "    # x = self.activation_func(x)\n",
        "    x = self.activation_func(x)\n",
        "    x = x.view(-1, self.maxpool_output_size2)\n",
        "\n",
        "    x = self.fc1(x)\n",
        "\n",
        "    x = self.activation_func(x)\n",
        "    # x = self.fc2(x)\n",
        "    # x = self.activation_func(x)\n",
        "    x = self.fc3(x)\n",
        "    # x = self.activation_func(x)\n",
        "\n",
        "    # x = self.activation_func7(x)\n",
        "    return x\n",
        "\n",
        "  def get_loss(self, learning_rate):\n",
        "    loss = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "    return loss, optimizer\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHaayoLKRwaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = MyCNN()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SbsGk9qjpmY",
        "colab_type": "code",
        "outputId": "5bfd9919-8d44-4eac-b70f-8cbe7c6765bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def visualize_network(net):\n",
        "    # Visualize the architecture of the model\n",
        "    # We need to give the net a fake input for this library to visualize the architecture\n",
        "    fake_input = Variable(torch.zeros((1, image_dims[0], image_dims[1], image_dims[2]))).to(device)\n",
        "    outputs = net(fake_input)\n",
        "    # Plot the DAG (Directed Acyclic Graph) of the model\n",
        "    return make_dot(outputs, dict(net.named_parameters()))\n",
        "\n",
        "# Define what device we want to use\n",
        "device = 'cuda' # 'cpu' if we want to not use the gpu\n",
        "# Initialize the model, loss, and optimization function\n",
        "net = MyCNN()\n",
        "# This tells our model to send all of the tensors and operations to the GPU (or keep them at the CPU if we're not using GPU)\n",
        "net.to(device)\n",
        "# \n",
        "visualize_network(net)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7f4f780b34e0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"388pt\" height=\"734pt\"\n viewBox=\"0.00 0.00 387.50 734.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 730)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-730 383.5,-730 383.5,4 -4,4\"/>\n<!-- 139979292804936 -->\n<g id=\"node1\" class=\"node\">\n<title>139979292804936</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"292,-21 188,-21 188,0 292,0 292,-21\"/>\n<text text-anchor=\"middle\" x=\"240\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n</g>\n<!-- 139979292803648 -->\n<g id=\"node2\" class=\"node\">\n<title>139979292803648</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"175,-91 121,-91 121,-57 175,-57 175,-91\"/>\n<text text-anchor=\"middle\" x=\"148\" y=\"-77.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc3.bias</text>\n<text text-anchor=\"middle\" x=\"148\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (6)</text>\n</g>\n<!-- 139979292803648&#45;&gt;139979292804936 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139979292803648&#45;&gt;139979292804936</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M172.6543,-56.9832C186.1894,-47.641 202.8926,-36.1122 216.278,-26.8734\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"218.2865,-29.7398 224.5283,-21.1788 214.3102,-23.9788 218.2865,-29.7398\"/>\n</g>\n<!-- 139979292805608 -->\n<g id=\"node3\" class=\"node\">\n<title>139979292805608</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"287,-84.5 193,-84.5 193,-63.5 287,-63.5 287,-84.5\"/>\n<text text-anchor=\"middle\" x=\"240\" y=\"-70.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 139979292805608&#45;&gt;139979292804936 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139979292805608&#45;&gt;139979292804936</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M240,-63.2281C240,-54.5091 240,-41.9699 240,-31.3068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"243.5001,-31.1128 240,-21.1128 236.5001,-31.1129 243.5001,-31.1128\"/>\n</g>\n<!-- 139979292803872 -->\n<g id=\"node4\" class=\"node\">\n<title>139979292803872</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"291,-154.5 187,-154.5 187,-133.5 291,-133.5 291,-154.5\"/>\n<text text-anchor=\"middle\" x=\"239\" y=\"-140.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddmmBackward</text>\n</g>\n<!-- 139979292803872&#45;&gt;139979292805608 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139979292803872&#45;&gt;139979292805608</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M239.1519,-133.3685C239.2972,-123.1925 239.5206,-107.5606 239.7016,-94.8912\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"243.2034,-94.7806 239.8467,-84.7315 236.2041,-94.6805 243.2034,-94.7806\"/>\n</g>\n<!-- 139979293366928 -->\n<g id=\"node5\" class=\"node\">\n<title>139979293366928</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"175,-231 121,-231 121,-197 175,-197 175,-231\"/>\n<text text-anchor=\"middle\" x=\"148\" y=\"-217.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc1.bias</text>\n<text text-anchor=\"middle\" x=\"148\" y=\"-204.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (64)</text>\n</g>\n<!-- 139979293366928&#45;&gt;139979292803872 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139979293366928&#45;&gt;139979292803872</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M170.4944,-196.6966C184.7034,-185.7666 202.9745,-171.7119 217.0735,-160.8666\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"219.447,-163.4565 225.2393,-154.5852 215.179,-157.9081 219.447,-163.4565\"/>\n</g>\n<!-- 139979293364352 -->\n<g id=\"node6\" class=\"node\">\n<title>139979293364352</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"284.5,-224.5 193.5,-224.5 193.5,-203.5 284.5,-203.5 284.5,-224.5\"/>\n<text text-anchor=\"middle\" x=\"239\" y=\"-210.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ViewBackward</text>\n</g>\n<!-- 139979293364352&#45;&gt;139979292803872 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139979293364352&#45;&gt;139979292803872</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M239,-203.3685C239,-193.1925 239,-177.5606 239,-164.8912\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"242.5001,-164.7315 239,-154.7315 235.5001,-164.7316 242.5001,-164.7315\"/>\n</g>\n<!-- 139979293366984 -->\n<g id=\"node7\" class=\"node\">\n<title>139979293366984</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"286,-294.5 192,-294.5 192,-273.5 286,-273.5 286,-294.5\"/>\n<text text-anchor=\"middle\" x=\"239\" y=\"-280.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 139979293366984&#45;&gt;139979293364352 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139979293366984&#45;&gt;139979293364352</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M239,-273.3685C239,-263.1925 239,-247.5606 239,-234.8912\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"242.5001,-234.7315 239,-224.7315 235.5001,-234.7316 242.5001,-234.7315\"/>\n</g>\n<!-- 139979293365192 -->\n<g id=\"node8\" class=\"node\">\n<title>139979293365192</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"329,-358 149,-358 149,-337 329,-337 329,-358\"/>\n<text text-anchor=\"middle\" x=\"239\" y=\"-344.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MaxPool2DWithIndicesBackward</text>\n</g>\n<!-- 139979293365192&#45;&gt;139979293366984 -->\n<g id=\"edge7\" class=\"edge\">\n<title>139979293365192&#45;&gt;139979293366984</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M239,-336.7281C239,-328.0091 239,-315.4699 239,-304.8068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"242.5001,-304.6128 239,-294.6128 235.5001,-304.6129 242.5001,-304.6128\"/>\n</g>\n<!-- 139979293366480 -->\n<g id=\"node9\" class=\"node\">\n<title>139979293366480</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"286,-415 192,-415 192,-394 286,-394 286,-415\"/>\n<text text-anchor=\"middle\" x=\"239\" y=\"-401.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 139979293366480&#45;&gt;139979293365192 -->\n<g id=\"edge8\" class=\"edge\">\n<title>139979293366480&#45;&gt;139979293365192</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M239,-393.7787C239,-386.6134 239,-376.9517 239,-368.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"242.5001,-368.1732 239,-358.1732 235.5001,-368.1732 242.5001,-368.1732\"/>\n</g>\n<!-- 139979293364296 -->\n<g id=\"node10\" class=\"node\">\n<title>139979293364296</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"317.5,-472 160.5,-472 160.5,-451 317.5,-451 317.5,-472\"/>\n<text text-anchor=\"middle\" x=\"239\" y=\"-458.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n</g>\n<!-- 139979293364296&#45;&gt;139979293366480 -->\n<g id=\"edge9\" class=\"edge\">\n<title>139979293364296&#45;&gt;139979293366480</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M239,-450.7787C239,-443.6134 239,-433.9517 239,-425.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"242.5001,-425.1732 239,-415.1732 235.5001,-425.1732 242.5001,-425.1732\"/>\n</g>\n<!-- 139979293366032 -->\n<g id=\"node11\" class=\"node\">\n<title>139979293366032</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"180,-535.5 0,-535.5 0,-514.5 180,-514.5 180,-535.5\"/>\n<text text-anchor=\"middle\" x=\"90\" y=\"-521.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MaxPool2DWithIndicesBackward</text>\n</g>\n<!-- 139979293366032&#45;&gt;139979293364296 -->\n<g id=\"edge10\" class=\"edge\">\n<title>139979293366032&#45;&gt;139979293364296</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M114.9392,-514.3715C139.5429,-503.8861 177.3449,-487.7758 204.7558,-476.094\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"206.1522,-479.3036 213.9794,-472.1631 203.4077,-472.864 206.1522,-479.3036\"/>\n</g>\n<!-- 139979293365024 -->\n<g id=\"node12\" class=\"node\">\n<title>139979293365024</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"137,-599 43,-599 43,-578 137,-578 137,-599\"/>\n<text text-anchor=\"middle\" x=\"90\" y=\"-585.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">ReluBackward0</text>\n</g>\n<!-- 139979293365024&#45;&gt;139979293366032 -->\n<g id=\"edge11\" class=\"edge\">\n<title>139979293365024&#45;&gt;139979293366032</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M90,-577.7281C90,-569.0091 90,-556.4699 90,-545.8068\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"93.5001,-545.6128 90,-535.6128 86.5001,-545.6129 93.5001,-545.6128\"/>\n</g>\n<!-- 139979293365528 -->\n<g id=\"node13\" class=\"node\">\n<title>139979293365528</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"168.5,-656 11.5,-656 11.5,-635 168.5,-635 168.5,-656\"/>\n<text text-anchor=\"middle\" x=\"90\" y=\"-642.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">CudnnConvolutionBackward</text>\n</g>\n<!-- 139979293365528&#45;&gt;139979293365024 -->\n<g id=\"edge12\" class=\"edge\">\n<title>139979293365528&#45;&gt;139979293365024</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M90,-634.7787C90,-627.6134 90,-617.9517 90,-609.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"93.5001,-609.1732 90,-599.1732 86.5001,-609.1732 93.5001,-609.1732\"/>\n</g>\n<!-- 139979292862448 -->\n<g id=\"node14\" class=\"node\">\n<title>139979292862448</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"84.5,-726 3.5,-726 3.5,-692 84.5,-692 84.5,-726\"/>\n<text text-anchor=\"middle\" x=\"44\" y=\"-712.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv1.weight</text>\n<text text-anchor=\"middle\" x=\"44\" y=\"-699.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (16, 1, 3, 3)</text>\n</g>\n<!-- 139979292862448&#45;&gt;139979293365528 -->\n<g id=\"edge13\" class=\"edge\">\n<title>139979292862448&#45;&gt;139979293365528</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M56.3272,-691.9832C62.4107,-683.5853 69.7742,-673.4204 76.0621,-664.7404\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"79.0945,-666.5204 82.1266,-656.3687 73.4256,-662.4138 79.0945,-666.5204\"/>\n</g>\n<!-- 139979292860488 -->\n<g id=\"node15\" class=\"node\">\n<title>139979292860488</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"171,-726 103,-726 103,-692 171,-692 171,-726\"/>\n<text text-anchor=\"middle\" x=\"137\" y=\"-712.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv1.bias</text>\n<text text-anchor=\"middle\" x=\"137\" y=\"-699.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (16)</text>\n</g>\n<!-- 139979292860488&#45;&gt;139979293365528 -->\n<g id=\"edge14\" class=\"edge\">\n<title>139979292860488&#45;&gt;139979293365528</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M124.4049,-691.9832C118.1237,-683.4969 110.5069,-673.2062 104.0384,-664.4668\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"106.8071,-662.3243 98.0445,-656.3687 101.1806,-666.4888 106.8071,-662.3243\"/>\n</g>\n<!-- 139979293366144 -->\n<g id=\"node16\" class=\"node\">\n<title>139979293366144</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"279.5,-542 198.5,-542 198.5,-508 279.5,-508 279.5,-542\"/>\n<text text-anchor=\"middle\" x=\"239\" y=\"-528.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv2.weight</text>\n<text text-anchor=\"middle\" x=\"239\" y=\"-515.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (32, 16, 3, 3)</text>\n</g>\n<!-- 139979293366144&#45;&gt;139979293364296 -->\n<g id=\"edge15\" class=\"edge\">\n<title>139979293366144&#45;&gt;139979293364296</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M239,-507.9832C239,-500.1157 239,-490.6973 239,-482.4019\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"242.5001,-482.3686 239,-472.3687 235.5001,-482.3687 242.5001,-482.3686\"/>\n</g>\n<!-- 139979293365920 -->\n<g id=\"node17\" class=\"node\">\n<title>139979293365920</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"366,-542 298,-542 298,-508 366,-508 366,-542\"/>\n<text text-anchor=\"middle\" x=\"332\" y=\"-528.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">conv2.bias</text>\n<text text-anchor=\"middle\" x=\"332\" y=\"-515.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (32)</text>\n</g>\n<!-- 139979293365920&#45;&gt;139979293364296 -->\n<g id=\"edge16\" class=\"edge\">\n<title>139979293365920&#45;&gt;139979293364296</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M307.0777,-507.9832C293.3955,-498.641 276.5107,-487.1122 262.9799,-477.8734\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"264.872,-474.9273 254.6398,-472.1788 260.9248,-480.7082 264.872,-474.9273\"/>\n</g>\n<!-- 139979293364520 -->\n<g id=\"node18\" class=\"node\">\n<title>139979293364520</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"375.5,-224.5 302.5,-224.5 302.5,-203.5 375.5,-203.5 375.5,-224.5\"/>\n<text text-anchor=\"middle\" x=\"339\" y=\"-210.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n</g>\n<!-- 139979293364520&#45;&gt;139979292803872 -->\n<g id=\"edge17\" class=\"edge\">\n<title>139979293364520&#45;&gt;139979292803872</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M323.8122,-203.3685C307.492,-191.9444 281.3486,-173.644 262.398,-160.3786\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"264.2026,-157.3695 254.0031,-154.5022 260.1883,-163.1042 264.2026,-157.3695\"/>\n</g>\n<!-- 139979293366872 -->\n<g id=\"node19\" class=\"node\">\n<title>139979293366872</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"373.5,-301 304.5,-301 304.5,-267 373.5,-267 373.5,-301\"/>\n<text text-anchor=\"middle\" x=\"339\" y=\"-287.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc1.weight</text>\n<text text-anchor=\"middle\" x=\"339\" y=\"-274.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (64, 1568)</text>\n</g>\n<!-- 139979293366872&#45;&gt;139979293364520 -->\n<g id=\"edge18\" class=\"edge\">\n<title>139979293366872&#45;&gt;139979293364520</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M339,-266.6966C339,-257.0634 339,-245.003 339,-234.8518\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"342.5001,-234.7912 339,-224.7913 335.5001,-234.7913 342.5001,-234.7912\"/>\n</g>\n<!-- 139979292806168 -->\n<g id=\"node20\" class=\"node\">\n<title>139979292806168</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"379.5,-84.5 306.5,-84.5 306.5,-63.5 379.5,-63.5 379.5,-84.5\"/>\n<text text-anchor=\"middle\" x=\"343\" y=\"-70.9\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">TBackward</text>\n</g>\n<!-- 139979292806168&#45;&gt;139979292804936 -->\n<g id=\"edge19\" class=\"edge\">\n<title>139979292806168&#45;&gt;139979292804936</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M325.5275,-63.2281C309.1519,-53.1325 284.4682,-37.9149 265.8209,-26.4187\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"267.5636,-23.3814 257.2145,-21.1128 263.8901,-29.3401 267.5636,-23.3814\"/>\n</g>\n<!-- 139979293365976 -->\n<g id=\"node21\" class=\"node\">\n<title>139979293365976</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"376.5,-161 309.5,-161 309.5,-127 376.5,-127 376.5,-161\"/>\n<text text-anchor=\"middle\" x=\"343\" y=\"-147.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">fc3.weight</text>\n<text text-anchor=\"middle\" x=\"343\" y=\"-134.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (6, 64)</text>\n</g>\n<!-- 139979293365976&#45;&gt;139979292806168 -->\n<g id=\"edge20\" class=\"edge\">\n<title>139979293365976&#45;&gt;139979292806168</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M343,-126.6966C343,-117.0634 343,-105.003 343,-94.8518\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"346.5001,-94.7912 343,-84.7913 339.5001,-94.7913 346.5001,-94.7912\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_9CTlb4Yx7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define training parameters\n",
        "batch_size = 128\n",
        "learning_rate = 1e-2\n",
        "n_epochs = 2\n",
        "# Get our data into the mini batch size that we defined\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size = batch_size, sampler=train_sampler, num_workers = 2)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size = 128, sampler=test_sampler, num_workers = 2)\n",
        "\n",
        "def train_model(net):\n",
        "    \"\"\" Train a the specified network.\n",
        "\n",
        "        Outputs a tuple with the following four elements\n",
        "        train_hist_x: the x-values (batch number) that the training set was \n",
        "            evaluated on.\n",
        "        train_loss_hist: the loss values for the training set corresponding to\n",
        "            the batch numbers returned in train_hist_x\n",
        "        test_hist_x: the x-values (batch number) that the test set was \n",
        "            evaluated on.\n",
        "        test_loss_hist: the loss values for the test set corresponding to\n",
        "            the batch numbers returned in test_hist_x\n",
        "    \"\"\" \n",
        "    loss, optimizer = net.get_loss(learning_rate)\n",
        "    # Define some parameters to keep track of metrics\n",
        "    print_every = 200\n",
        "    idx = 0\n",
        "    train_hist_x = []\n",
        "    train_loss_hist = []\n",
        "    test_hist_x = []\n",
        "    test_loss_hist = []\n",
        "\n",
        "    training_start_time = time.time()\n",
        "    # Loop for n_epochs\n",
        "    for epoch in range(n_epochs):\n",
        "        running_loss = 0.0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "\n",
        "            # Get inputs in right form\n",
        "            inputs, labels = data\n",
        "            inputs, labels = Variable(inputs).to(device), Variable(labels).to(device)\n",
        "            \n",
        "            # In Pytorch, We need to always remember to set the optimizer gradients to 0 before we recompute the new gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = net(inputs)\n",
        "            \n",
        "            # Compute the loss and find the loss with respect to each parameter of the model\n",
        "            loss_size = loss(outputs, labels)\n",
        "            loss_size.backward()\n",
        "            \n",
        "            # Change each parameter with respect to the recently computed loss.\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update statistics\n",
        "            running_loss += loss_size.data.item()\n",
        "            \n",
        "            # Print every 20th batch of an epoch\n",
        "            if (i % print_every) == print_every-1:\n",
        "                print(\"Epoch {}, Iteration {}\\t train_loss: {:.2f} took: {:.2f}s\".format(\n",
        "                    epoch + 1, i+1,running_loss / print_every, time.time() - start_time))\n",
        "                # Reset running loss and time\n",
        "                train_loss_hist.append(running_loss / print_every)\n",
        "                train_hist_x.append(idx)\n",
        "                running_loss = 0.0\n",
        "                start_time = time.time()\n",
        "            idx += 1\n",
        "\n",
        "        # At the end of the epoch, do a pass on the test set\n",
        "        total_test_loss = 0\n",
        "        for inputs, labels in test_loader:\n",
        "\n",
        "            # Wrap tensors in Variables\n",
        "            inputs, labels = Variable(inputs).to(device), Variable(labels).to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            test_outputs = net(inputs)\n",
        "            test_loss_size = loss(test_outputs, labels)\n",
        "            total_test_loss += test_loss_size.data.item()\n",
        "        test_loss_hist.append(total_test_loss / len(test_loader))\n",
        "        test_hist_x.append(idx)\n",
        "        print(\"Validation loss = {:.2f}\".format(\n",
        "            total_test_loss / len(test_loader)))\n",
        "\n",
        "    print(\"Training finished, took {:.2f}s\".format(\n",
        "        time.time() - training_start_time))\n",
        "    return train_hist_x, train_loss_hist, test_hist_x, test_loss_hist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGyZdjgNjf_h",
        "colab_type": "code",
        "outputId": "79bdd6a8-78be-4e69-d05e-af0bf87dc056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_hist_x, train_loss_hist, test_hist_x, test_loss_hist = train_model(net)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Iteration 200\t train_loss: 1.59 took: 2.08s\n",
            "Epoch 1, Iteration 400\t train_loss: 0.66 took: 1.77s\n",
            "Epoch 1, Iteration 600\t train_loss: 0.60 took: 1.73s\n",
            "Epoch 1, Iteration 800\t train_loss: 0.56 took: 1.84s\n",
            "Epoch 1, Iteration 1000\t train_loss: 0.56 took: 1.76s\n",
            "Epoch 1, Iteration 1200\t train_loss: 0.54 took: 1.79s\n",
            "Epoch 1, Iteration 1400\t train_loss: 0.54 took: 1.73s\n",
            "Epoch 1, Iteration 1600\t train_loss: 0.54 took: 1.75s\n",
            "Epoch 1, Iteration 1800\t train_loss: 0.54 took: 1.77s\n",
            "Epoch 1, Iteration 2000\t train_loss: 0.53 took: 1.74s\n",
            "Epoch 1, Iteration 2200\t train_loss: 0.52 took: 1.92s\n",
            "Epoch 1, Iteration 2400\t train_loss: 0.51 took: 1.79s\n",
            "Epoch 1, Iteration 2600\t train_loss: 0.50 took: 1.68s\n",
            "Epoch 1, Iteration 2800\t train_loss: 0.50 took: 1.80s\n",
            "Epoch 1, Iteration 3000\t train_loss: 0.49 took: 1.80s\n",
            "Epoch 1, Iteration 3200\t train_loss: 0.48 took: 1.78s\n",
            "Epoch 1, Iteration 3400\t train_loss: 0.47 took: 1.71s\n",
            "Epoch 1, Iteration 3600\t train_loss: 0.46 took: 1.74s\n",
            "Epoch 1, Iteration 3800\t train_loss: 0.46 took: 1.65s\n",
            "Epoch 1, Iteration 4000\t train_loss: 0.45 took: 1.70s\n",
            "Epoch 1, Iteration 4200\t train_loss: 0.43 took: 1.68s\n",
            "Epoch 1, Iteration 4400\t train_loss: 0.44 took: 1.71s\n",
            "Epoch 1, Iteration 4600\t train_loss: 0.42 took: 1.70s\n",
            "Epoch 1, Iteration 4800\t train_loss: 0.41 took: 1.85s\n",
            "Epoch 1, Iteration 5000\t train_loss: 0.42 took: 1.80s\n",
            "Epoch 1, Iteration 5200\t train_loss: 0.41 took: 1.76s\n",
            "Epoch 1, Iteration 5400\t train_loss: 0.40 took: 1.70s\n",
            "Epoch 1, Iteration 5600\t train_loss: 0.41 took: 1.66s\n",
            "Validation loss = 0.40\n",
            "Epoch 2, Iteration 200\t train_loss: 0.41 took: 2.01s\n",
            "Epoch 2, Iteration 400\t train_loss: 0.41 took: 1.83s\n",
            "Epoch 2, Iteration 600\t train_loss: 0.41 took: 2.00s\n",
            "Epoch 2, Iteration 800\t train_loss: 0.41 took: 1.78s\n",
            "Epoch 2, Iteration 1000\t train_loss: 0.40 took: 1.79s\n",
            "Epoch 2, Iteration 1200\t train_loss: 0.40 took: 1.88s\n",
            "Epoch 2, Iteration 1400\t train_loss: 0.40 took: 1.77s\n",
            "Epoch 2, Iteration 1600\t train_loss: 0.39 took: 1.80s\n",
            "Epoch 2, Iteration 1800\t train_loss: 0.40 took: 1.68s\n",
            "Epoch 2, Iteration 2000\t train_loss: 0.40 took: 1.69s\n",
            "Epoch 2, Iteration 2200\t train_loss: 0.42 took: 1.74s\n",
            "Epoch 2, Iteration 2400\t train_loss: 0.39 took: 1.78s\n",
            "Epoch 2, Iteration 2600\t train_loss: 0.40 took: 1.67s\n",
            "Epoch 2, Iteration 2800\t train_loss: 0.40 took: 1.68s\n",
            "Epoch 2, Iteration 3000\t train_loss: 0.40 took: 1.72s\n",
            "Epoch 2, Iteration 3200\t train_loss: 0.40 took: 1.87s\n",
            "Epoch 2, Iteration 3400\t train_loss: 0.39 took: 1.90s\n",
            "Epoch 2, Iteration 3600\t train_loss: 0.39 took: 1.82s\n",
            "Epoch 2, Iteration 3800\t train_loss: 0.40 took: 1.69s\n",
            "Epoch 2, Iteration 4000\t train_loss: 0.38 took: 1.64s\n",
            "Epoch 2, Iteration 4200\t train_loss: 0.40 took: 1.79s\n",
            "Epoch 2, Iteration 4400\t train_loss: 0.39 took: 1.69s\n",
            "Epoch 2, Iteration 4600\t train_loss: 0.40 took: 1.68s\n",
            "Epoch 2, Iteration 4800\t train_loss: 0.40 took: 1.73s\n",
            "Epoch 2, Iteration 5000\t train_loss: 0.39 took: 1.77s\n",
            "Epoch 2, Iteration 5200\t train_loss: 0.38 took: 1.78s\n",
            "Epoch 2, Iteration 5400\t train_loss: 0.39 took: 1.78s\n",
            "Epoch 2, Iteration 5600\t train_loss: 0.39 took: 1.76s\n",
            "Validation loss = 0.40\n",
            "Training finished, took 110.13s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVNSsFzVji6W",
        "colab_type": "code",
        "outputId": "0e1f305b-40ed-48d8-dd0a-75e9318c1776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.plot(train_hist_x,train_loss_hist)\n",
        "plt.plot(test_hist_x,test_loss_hist)\n",
        "plt.legend(['train loss', 'validation loss'])\n",
        "plt.xlabel('Batch number')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlim(0,12000)\n",
        "plt.ylim(0,2)\n",
        "plt.show()\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQ13LfcF3Ji2",
        "colab_type": "code",
        "outputId": "d7c45f42-d211-43e0-adc9-3a593f4d77b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def get_accuracy(net, loader):\n",
        "    n_correct = 0\n",
        "    n_total = 0\n",
        "    for i, data in enumerate(loader, 0):\n",
        "        # Get inputs in right form\n",
        "        inputs, labels = data\n",
        "        inputs, labels = Variable(inputs).to(device), Variable(labels).to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = net(inputs)\n",
        "        n_correct += np.sum(np.argmax(outputs.cpu().detach().numpy(), axis=1) == labels.cpu().numpy())\n",
        "        n_total += labels.shape[0]\n",
        "    return n_correct/n_total\n",
        "print(\"Train accuracy is\", get_accuracy(net, train_loader))\n",
        "print(\"Test accuracy is\", get_accuracy(net, test_loader))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy is 0.8674371075125407\n",
            "Test accuracy is 0.8662009476369822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqMZxrWj47rA",
        "colab_type": "code",
        "outputId": "2f70b402-1c27-40d9-e260-2b1202a3f658",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "def examine_label(idx):\n",
        "    image, label = test_set[idx]\n",
        "    class_scores = net(Variable(image.unsqueeze(0)).to(device))\n",
        "    prediction = np.argmax(class_scores.cpu().detach().numpy())\n",
        "    confidence = class_scores.cpu().detach().numpy()\n",
        "    plt.imshow(image.squeeze(), cmap='gray')\n",
        "    plt.show()\n",
        "    print(prediction)\n",
        "    print(label)\n",
        "    print(max(confidence[0])/sum(confidence[0]))\n",
        "\n",
        "examine_label(11127)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH0jU/wPks5kITv4yAgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "2.4569053058240926\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSeuwv8R5NGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}